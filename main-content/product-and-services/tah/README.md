---
description: What is Training at Home (TAH)?
hidden: true
---

# Training at Home

<figure><img src="../../.gitbook/assets/IOTA-title.png" alt=""><figcaption></figcaption></figure>

Today, access to large-scale compute is concentrated in a few organizations, limiting innovation and slowing progress across the ecosystem. By enabling anyone to contribute hardware and collectively train powerful models, we lower the barrier to participation, unlock underutilized global compute, and empower a wider community of builders and researchers. This creates a more resilient, transparent, and scalable foundation for advancing open-source AI - one that grows stronger as more people join and contribute.

TAH is a decentralized, community-driven, and efficient pre-training platform. It is built on top of IOTA, a data- and pipeline-parallel training algorithm designed to operate on a network of heterogeneous, unreliable devices in adversarial and trustless environments. For more information on IOTA, please see the [IOTA documentation](../../subnets/subnet-9-iota/).

You can plug in any hardware you have access to and earn rewards for powering decentralized AI model training.&#x20;

We aim to solve one of the biggest challenges in open-source AI today: the absence of a decentralized, community-driven, and highly efficient pre-training platform.

#### Learn More

* [TAH User Guide](tah-user-guide.md)
* [Hardware & OS Requirements](hardware-requirements.md)
* [FAQs](faqs.md)
