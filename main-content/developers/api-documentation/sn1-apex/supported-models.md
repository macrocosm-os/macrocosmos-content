# Supported Models



**1. Meta-Llama 3.1 70B Instruct (Quantized)** &#x20;

`"hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4"`

_Description:_ A quantized version of Meta AI's 70-billion-parameter model, optimized for multilingual dialogue applications.

_Details:_

* **Model Size:** 70 billion parameters
* **Quantization:** INT4 using AutoAWQ
* **Use Cases:** Multilingual dialogue applications

_More Information:_ [Meta-Llama 3.1 70B Instruct - Hugging Face](https://huggingface.co/hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4)

***

**2. Mistral Small 3.1 24B Instruct**&#x20;

**`"mrfakename/mistral-small-3.1-24b-instruct-2503-hf"`**

_Description:_ A 24-billion-parameter instruction-tuned model, focusing on text generation tasks.

_Details:_

* **Model Size:** 24 billion parameters
* **Format:** Hugging Face Transformers
* **Use Cases:** Text generation tasks

_More Information:_ [Mistral Small 3.1 24B Instruct - Hugging Face](https://huggingface.co/mrfakename/mistral-small-3.1-24b-instruct-2503-hf)

***

**3. Gemma 3 27B (Upcoming)**

_Description:_ A 27-billion-parameter multimodal model from Google, capable of handling both text and image inputs.

_Details:_

* **Model Size:** 27 billion parameters
* **Capabilities:** Multimodal (text and image input, text output)
* **Use Cases:** Question answering, summarization, reasoning

_More Information:_ [Gemma 3 27B - Hugging Face](https://huggingface.co/google/gemma-3-27b-it)

***
