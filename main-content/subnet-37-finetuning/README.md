---
description: Bittensor can train the best models
---

# Subnet 37 - Finetuning

The drive behind subnet 37 is to bring the entire AI development pipeline into Bittensor, with finetuning as a critical step in the path towards this. We believe it will strongly support Bittensor’s founding vision - that AI can be built in an _economical, safe and decentralized way_.

Finetuning is costly, time consuming and highly limited by expertise. It requires hundreds of GPU hours, typically requiring SOTA hardware. But perhaps most importantly, it requires expert engineers, who are often scarce.&#x20;

Subnet 37 addresses these challenges by outsourcing the procurement process of computational resources and incentivising the best AI developers in the world to monetise their skills by competing to produce top models. This is also in collaboration with subnet 9, [Pre-training](../subnets/subnet-9-pre-training.md).

Our vision is to build an open-sourced catalog of models, each optimised for specialised tasks such as chatbots, math-solvers, programming assistants, recommendation bots, and more. Models in the catalog are already available to download on HuggingFace and will soon power several apps.

We aim to integrate the models we create into subnet 1 as base models for future agentic assistants. We see subnets 37 and [subnet 1](../subnets/subnet-1-apex/) evolving in tandem to produce ever-improving AI assistants. This will provide the additional benefit of user-feedback through subnet 1’s chat application, which will be used to continuously refine the models and their capabilities.

For more details about the subnet 37 R\&D work, take a look at our Substack articles:

* [Fine-tuning, finely tuned: How SN37 is delivering SOTA fine-tuning on Bittensor](https://macrocosmosai.substack.com/p/fine-tuning-finely-tuned-how-sn37)
* [Fine-tuning, harmonized: Taoverse and Macrocosmos team up on SN37](https://macrocosmosai.substack.com/p/fine-tuning-harmonized-macrocosmos)

Related resources

* [Website](https://www.macrocosmos.ai/sn37)
* [Dashboard](https://www.macrocosmos.ai/sn37/dashboard)
* [GitHub](https://github.com/macrocosm-os/finetuning)
* [Substack](https://macrocosmosai.substack.com/t/ai-fine-tuning)
* [Bittensor Discord](https://discord.com/channels/799672011265015819/1234881153832321024)
* [Macrocosmos Discord](https://discord.com/channels/1238450997848707082)
* [Cosmonauts - Macrocosmos Telegram](https://t.me/macrocosmosai)
* [Macrocosmos X](https://x.com/MacrocosmosAI)

\
